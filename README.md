# OlympicsKedro

[![Powered by Kedro](https://img.shields.io/badge/powered_by-kedro-ffc900?logo=kedro)](https://kedro.org)


## Dataset kaggle
[![Dataset](https://img.shields.io/badge/-Dataset_Olympics_Games-20BEFF?logo=kaggle&logoColor=white)](https://www.kaggle.com/datasets/the-guardian/olympic-games)



## Video presentaciÃ³n Ev2 
[![Video](https://img.shields.io/badge/-Video_Explicativo_OlympicsKedro-4285F4?logo=google-drive&logoColor=white)](https://drive.google.com/file/d/1YgcR6Xv4p7QSginYgnExgHLqoo-wqFcM/view?usp=sharing)


## ğŸ Crear entorno virtual

Antes de comenzar, crea un entorno virtual llamado `venv` y actÃ­valo:

```bash
python -m venv venv
source venv/bin/activate  #En Linux
venv\Scripts\activate  #En Windows
```

Una vez activado, puedes instalar las dependencias como se indica mÃ¡s abajo.

---

## ğŸ§± DescripciÃ³n general del proyecto

Este proyecto implementa un pipeline de Machine Learning sobre datos histÃ³ricos de los Juegos OlÃ­mpicos utilizando:

**Kedro** â†’ para estructurar y ejecutar pipelines de datos reproducibles

**DVC** â†’ para versionar datasets y modelos

**Airflow** â†’ para orquestar la ejecuciÃ³n automatizada de pipelines

**Docker** â†’ para desplegar y ejecutar todo el ecosistema en contenedores

## El proyecto incluye pipelines de:

**Data Engineering** (preprocesamiento y limpieza)

**Classification** (5 modelos de clasificaciÃ³n)

**Regression** (modelos de predicciÃ³n continua)

**Unsupervised Learning** (clustering, reducciÃ³n dimensional, anomalÃ­as)

**Integration** (combinaciÃ³n supervisado + no supervisado)

**Pattern Analysis** (anÃ¡lisis de patrones por cluster)

**Reporting** (generaciÃ³n de mÃ©tricas y resultados)

---

## ğŸ“Œ Reglas y pautas

Para sacar el mÃ¡ximo provecho de esta plantilla:

* No elimines ninguna lÃ­nea del archivo `.gitignore` proporcionado.
* AsegÃºrate de que tus resultados puedan ser reproducidos siguiendo una convenciÃ³n de ingenierÃ­a de datos.
* **No subas datos** a tu repositorio.
* **No subas credenciales** ni configuraciones locales. Guarda todo eso en el directorio `conf/local/`.

---

## ğŸ“¦ CÃ³mo instalar las dependencias

Declara las dependencias necesarias en el archivo `requirements.txt`.

Para instalarlas, ejecuta:

```
pip install -r requirements.txt
```

---

## â–¶ï¸ CÃ³mo ejecutar tu pipeline de Kedro

Puedes ejecutar tu proyecto Kedro con:

```
kedro run
```

## Ejecutar pipelines especÃ­ficos

```
ğŸ”§ Pipelines Individuales:
kedro run --pipeline=data_engineering
kedro run --pipeline=classification
kedro run --pipeline=regression
kedro run --pipeline=unsupervised
kedro run --pipeline=integration
kedro run --pipeline=pattern_analysis
kedro run --pipeline=innovation
kedro run --pipeline=reporting
kedro run --pipeline=reporting_unsupervised

ğŸš€ Pipelines Combinados:
kedro run --pipeline=supervised_learning (clasificaciÃ³n + regresiÃ³n)
kedro run --pipeline=ml_pipelines (supervisado + no supervisado)
kedro run --pipeline=analysis_pipelines (no supervisado + anÃ¡lisis patrones + reporting)
kedro run --pipeline=advanced_analysis (no supervisado + anÃ¡lisis patrones + innovaciÃ³n)
kedro run --pipeline=complete_analysis (anÃ¡lisis completo con innovaciÃ³n)
kedro run --pipeline=complete_modeling (modelado completo)
kedro run --pipeline=demo_pipeline (demostraciÃ³n rÃ¡pida)

âš¡ Pipelines RÃ¡pidos:
kedro run --pipeline=quick_test (solo data engineering + clasificaciÃ³n)
kedro run --pipeline=data_processing (solo procesamiento de datos)
kedro run --pipeline=model_training (solo entrenamiento de modelos)

ğŸ¯ Pipeline Completo:
kedro run o kedro run --pipeline=full_pipeline (EJECUTA TODO)

ğŸ”§ Pipelines de Desarrollo:
kedro run --pipeline=full_without_reporting (todo excepto reporting)
kedro run --pipeline=full_without_innovation (todo excepto innovaciÃ³n)

```

---

## ğŸ’¾ Control de versiones con DVC

El proyecto utiliza DVC (Data Version Control) para rastrear datasets y modelos.
Pasos bÃ¡sicos:

```
dvc init
dvc add data/01_raw data/02_intermediate data/07_model_output
git add .
git commit -m "Track data with DVC"
```

Para guardar versiones de los datos:

```
dvc push
```

---

## â˜ï¸ OrquestaciÃ³n con Apache Airflow

El DAG principal se llama olympicskedro_pipeline
y se encuentra en:

```
airflow_dags/olympicskedro_dag.py
```

Levantar Airflow con Docker

AsegÃºrate de tener Docker corriendo y ejecuta:

```
docker compose up -d
```

Accede a la interfaz web:

ğŸ‘‰ http://localhost:8080

Credenciales por defecto:

**Usuario:** admin

**ContraseÃ±a:** admin


Ejecuta manualmente el DAG desde la interfaz para correr todo el pipeline Kedro dentro de los contenedores.

---

## ğŸ³ Docker

[![Docker](https://img.shields.io/badge/-Docker-2496ED?logo=docker&logoColor=white)](https://www.docker.com)


El proyecto se ejecuta dentro de un entorno Dockerizado.

Construir las imÃ¡genes

```
docker compose build --no-cache
```

Iniciar todos los servicios

```
docker compose up -d
```

Esto levantarÃ¡:

- PostgreSQL (base de datos de Airflow)

- Airflow Webserver

- Airflow Scheduler

---
## ğŸ“Š Resultados y MÃ©tricas

### Modelos de ClasificaciÃ³n (PredicciÃ³n de Medallas)
* Mejor modelo: Logistic Regression (AUC: 0.516)
* Algoritmos probados: Random Forest, XGBoost, Gradient Boosting, LightGBM, SVM
* MÃ©tricas: AUC-ROC, F1-Score, Precision, Recall, Accuracy

### Modelos de RegresiÃ³n (PredicciÃ³n de GDP)
* Mejor modelo: Ensemble (RÂ²: > 0.7)
* Algoritmos: Random Forest, Gradient Boosting, Ridge, Lasso, XGBoost
* MÃ©tricas: RMSE, MAE, RÂ², MAPE

### AnÃ¡lisis No Supervisado
* Clustering: 3 algoritmos implementados (K-Means, DBSCAN, JerÃ¡rquico)
* ReducciÃ³n dimensional: PCA y t-SNE
* DetecciÃ³n de anomalÃ­as: Isolation Forest
* MÃ©tricas: Silhouette Score, Davies-Bouldin, Calinski-Harabasz

### IntegraciÃ³n Supervisado + No Supervisado
* Enfoque: Clusters como features para modelos supervisados
* Resultado: AnÃ¡lisis comparativo de mejora de rendimiento
---
## ğŸ—ï¸ Arquitectura del Proyecto
```
olympicskedro/
â”œâ”€â”€ conf/                    # ConfiguraciÃ³n
â”‚   â”œâ”€â”€ base/               # ConfiguraciÃ³n base
â”‚   â”‚   â”œâ”€â”€ catalog.yml     # DefiniciÃ³n de datasets
â”‚   â”‚   â””â”€â”€ parameters.yml  # ParÃ¡metros configurables
â”œâ”€â”€ data/                   # Datos y modelos
â”‚   â”œâ”€â”€ 01_raw/             # Datos originales
â”‚   â”œâ”€â”€ 02_intermediate/    # Datos procesados  
â”‚   â”œâ”€â”€ 06_models/          # Modelos entrenados
â”‚   â”œâ”€â”€ 07_model_output/    # Resultados de modelos
â”‚   â””â”€â”€ 08_reporting/       # Reportes y mÃ©tricas
â”œâ”€â”€ docs/                   # DocumentaciÃ³n tÃ©cnica
â”œâ”€â”€ notebooks/              # AnÃ¡lisis exploratorios
â”œâ”€â”€ src/olympicskedro/pipelines/  # Pipelines de procesamiento
â”‚   â”œâ”€â”€ data_engineering/   # IngenierÃ­a de datos
â”‚   â”œâ”€â”€ classification/     # Modelos de clasificaciÃ³n
â”‚   â”œâ”€â”€ regression/         # Modelos de regresiÃ³n
â”‚   â”œâ”€â”€ unsupervised_learning/     # AnÃ¡lisis no supervisado
â”‚   â”œâ”€â”€ integration/        # IntegraciÃ³n supervisado + no supervisado
â”‚   â”œâ”€â”€ pattern_analysis/   # AnÃ¡lisis de patrones
â”‚   â””â”€â”€ reporting/          # GeneraciÃ³n de reportes
â”œâ”€â”€ airflow_dags/           # OrquestaciÃ³n con Airflow
â””â”€â”€ docker/                 # ConfiguraciÃ³n Docker
```

---

## ğŸ”„ Flujo de Datos
1. Ingesta: Datos originales de Olympics (summer.csv, winter.csv, dictionary.csv)
2. Preprocesamiento: Limpieza, transformaciÃ³n y feature engineering
3. Modelado Supervisado: ClasificaciÃ³n y regresiÃ³n
4. Modelado No Supervisado: Clustering, reducciÃ³n dimensional, detecciÃ³n de anomalÃ­as
5. IntegraciÃ³n: CombinaciÃ³n de tÃ©cnicas supervisadas y no supervisadas
6. Pattern Analysis: AnÃ¡lisis profundo de clusters y patrones
7. Reporting: GeneraciÃ³n de mÃ©tricas y visualizaciones

---
## ğŸ› ï¸ Stack TecnolÃ³gico

**Framework ML:** Kedro

**OrquestaciÃ³n:** Apache Airflow

**Versionado:** DVC + Git

**Contenedores:** Docker + Docker Compose

**Machine Learning:** Scikit-learn, XGBoost, LightGBM

**AnÃ¡lisis No Supervisado:** UMAP, HDBSCAN, SHAP, Plotly

**VisualizaciÃ³n:** Matplotlib, Seaborn, Plotly

---
## ğŸ§ª CÃ³mo probar tu proyecto Kedro

Revisa el archivo `tests/test_run.py` para ver ejemplos de cÃ³mo escribir tus pruebas. Puedes ejecutarlas con:

```
pytest
```

Puedes configurar el umbral de cobertura de pruebas en el archivo `pyproject.toml`, en la secciÃ³n `[tool.coverage.report]`.

---

## ğŸ“š Dependencias del proyecto

Para ver y actualizar las dependencias de el proyecto, usa el archivo `requirements.txt`.

InstÃ¡lalas con:

```
pip install -r requirements.txt
```

---

## ğŸ““ CÃ³mo trabajar con Kedro y notebooks

> ğŸ’¡ Al usar `kedro jupyter` o `kedro ipython`, tendrÃ¡s acceso automÃ¡tico a las siguientes variables en tu notebook: `context`, `session`, `catalog` y `pipelines`.

Jupyter, JupyterLab e IPython ya estÃ¡n incluidos por defecto en los requerimientos del proyecto. Una vez que ejecutes:

```
pip install -r requirements.txt
```

No necesitas pasos adicionales.

### Usar Jupyter

Instala Jupyter si aÃºn no lo tienes:

```
pip install jupyter
```

Inicia un servidor local de notebooks:

```
kedro jupyter notebook
```

### Usar JupyterLab

InstÃ¡lalo con:

```
pip install jupyterlab
```

Y luego ejecÃºtalo con:

```
kedro jupyter lab
```

### Usar IPython

Si prefieres iniciar una sesiÃ³n interactiva con IPython:

```
kedro ipython
```

---

## ğŸš« CÃ³mo ignorar las salidas de celdas de los notebooks en git

Para eliminar automÃ¡ticamente el contenido de las celdas de salida antes de hacer commits a git, puedes usar herramientas como `nbstripout`.

Por ejemplo, puedes aÃ±adir un *hook* con:

```
nbstripout --install
```

> âš ï¸ Las salidas de tus celdas se mantendrÃ¡n localmente.

---

## ğŸ“¦ Empaquetar tu proyecto Kedro

Consulta la documentaciÃ³n oficial de Kedro para mÃ¡s informaciÃ³n sobre cÃ³mo generar documentaciÃ³n del proyecto y empaquetarlo para su distribuciÃ³n.

---
## ğŸ‘¥ Autores
**Gonzalo Gallardo**

**Alan Barria**