# OlympicsKedro

[![Powered by Kedro](https://img.shields.io/badge/powered_by-kedro-ffc900?logo=kedro)](https://kedro.org)

## Dataset kaggle
https://www.kaggle.com/datasets/the-guardian/olympic-games

## Video presentaciÃ³n Ev2 
https://drive.google.com/file/d/1ufLL5GsWMHaNYclvSCpVqR4Nqa5dyV99/view?usp=sharing
[![Video Explicativo OlympicsKedro](https://img.shields.io/badge/Video%20Explicativo-OlympicsKedro-blue?logo=google-drive)](https://drive.google.com/file/d/10TGaQiC0rRztdoMYyrjEVfpetHDd8PZD/view?usp=sharing)


## ğŸ Crear entorno virtual

Antes de comenzar, crea un entorno virtual llamado `venv` y actÃ­valo:

```bash
python -m venv venv
source venv/bin/activate  #En Linux
venv\Scripts\activate  #En Windows
```

Una vez activado, puedes instalar las dependencias como se indica mÃ¡s abajo.

---

## ğŸ§± DescripciÃ³n general del proyecto

Este proyecto implementa un pipeline de Machine Learning sobre datos histÃ³ricos de los Juegos OlÃ­mpicos utilizando:

Kedro â†’ para estructurar y ejecutar pipelines de datos reproducibles

DVC â†’ para versionar datasets y modelos

Airflow â†’ para orquestar la ejecuciÃ³n automatizada de pipelines

Docker â†’ para desplegar y ejecutar todo el ecosistema en contenedores

## El proyecto incluye pipelines de:

Data Engineering (preprocesamiento y limpieza)

Classification (5 modelos de clasificaciÃ³n)

Regression (modelos de predicciÃ³n continua)

Reporting (generaciÃ³n de mÃ©tricas y resultados)

---

## ğŸ“Œ Reglas y pautas

Para sacar el mÃ¡ximo provecho de esta plantilla:

* No elimines ninguna lÃ­nea del archivo `.gitignore` proporcionado.
* AsegÃºrate de que tus resultados puedan ser reproducidos siguiendo una convenciÃ³n de ingenierÃ­a de datos.
* **No subas datos** a tu repositorio.
* **No subas credenciales** ni configuraciones locales. Guarda todo eso en el directorio `conf/local/`.

---

## ğŸ“¦ CÃ³mo instalar las dependencias

Declara las dependencias necesarias en el archivo `requirements.txt`.

Para instalarlas, ejecuta:

```
pip install -r requirements.txt
```

---

## â–¶ï¸ CÃ³mo ejecutar tu pipeline de Kedro

Puedes ejecutar tu proyecto Kedro con:

```
kedro run
```

## Ejecutar pipelines especÃ­ficos

```
kedro run --pipeline=data_engineering
kedro run --pipeline=classification
kedro run --pipeline=regression
```

---

## ğŸ’¾ Control de versiones con DVC

El proyecto utiliza DVC (Data Version Control) para rastrear datasets y modelos.
Pasos bÃ¡sicos:

```
dvc init
dvc add data/01_raw data/02_intermediate data/07_model_output
git add .
git commit -m "Track data with DVC"
```

Para guardar versiones de los datos:

```
dvc push
```

---

## â˜ï¸ OrquestaciÃ³n con Apache Airflow

El DAG principal se llama olympicskedro_pipeline
y se encuentra en:

```
airflow_dags/olympicskedro_dag.py
```

Levantar Airflow con Docker

AsegÃºrate de tener Docker corriendo y ejecuta:

```
docker compose up -d
```

Accede a la interfaz web:

ğŸ‘‰ http://localhost:8080

Credenciales por defecto:

**Usuario:** admin
**ContraseÃ±a:** admin


Ejecuta manualmente el DAG desde la interfaz para correr todo el pipeline Kedro dentro de los contenedores.

---

## ğŸ³ Docker

(https://www.docker.com)

El proyecto se ejecuta dentro de un entorno Dockerizado.

Construir las imÃ¡genes

```
docker compose build --no-cache
```

Iniciar todos los servicios

```
docker compose up -d
```

Esto levantarÃ¡:

- PostgreSQL (base de datos de Airflow)

- Airflow Webserver

- Airflow Scheduler

---

## ğŸ§ª CÃ³mo probar tu proyecto Kedro

Revisa el archivo `tests/test_run.py` para ver ejemplos de cÃ³mo escribir tus pruebas. Puedes ejecutarlas con:

```
pytest
```

Puedes configurar el umbral de cobertura de pruebas en el archivo `pyproject.toml`, en la secciÃ³n `[tool.coverage.report]`.

---

## ğŸ“š Dependencias del proyecto

Para ver y actualizar las dependencias de el proyecto, usa el archivo `requirements.txt`.

InstÃ¡lalas con:

```
pip install -r requirements.txt
```

---

## ğŸ““ CÃ³mo trabajar con Kedro y notebooks

> ğŸ’¡ Al usar `kedro jupyter` o `kedro ipython`, tendrÃ¡s acceso automÃ¡tico a las siguientes variables en tu notebook: `context`, `session`, `catalog` y `pipelines`.

Jupyter, JupyterLab e IPython ya estÃ¡n incluidos por defecto en los requerimientos del proyecto. Una vez que ejecutes:

```
pip install -r requirements.txt
```

No necesitas pasos adicionales.

### Usar Jupyter

Instala Jupyter si aÃºn no lo tienes:

```
pip install jupyter
```

Inicia un servidor local de notebooks:

```
kedro jupyter notebook
```

### Usar JupyterLab

InstÃ¡lalo con:

```
pip install jupyterlab
```

Y luego ejecÃºtalo con:

```
kedro jupyter lab
```

### Usar IPython

Si prefieres iniciar una sesiÃ³n interactiva con IPython:

```
kedro ipython
```

---

## ğŸš« CÃ³mo ignorar las salidas de celdas de los notebooks en git

Para eliminar automÃ¡ticamente el contenido de las celdas de salida antes de hacer commits a git, puedes usar herramientas como `nbstripout`.

Por ejemplo, puedes aÃ±adir un *hook* con:

```
nbstripout --install
```

> âš ï¸ Las salidas de tus celdas se mantendrÃ¡n localmente.

---

## ğŸ“¦ Empaquetar tu proyecto Kedro

Consulta la documentaciÃ³n oficial de Kedro para mÃ¡s informaciÃ³n sobre cÃ³mo generar documentaciÃ³n del proyecto y empaquetarlo para su distribuciÃ³n.
